[{"content":"Context DiscoTech (Discover Caltech) was a 2 day event, where I had the chance to visit Caltech. There, I attended a mock lecture on information theory by Dr. Michelle Effros. I found it interesting enough for me to share here!\nInformation Theory Basic Ideas of Information Theory Focuses on 2 questions:\n How to represent information How to transfer information  Need to predict unpredictable events to do so\nPredicting Unpredictable Events Imagine you want be a psychic\n How will you decide who is good? By testing who is the best at predicting the future  A coin will land heads (1 at $p$) or tails (0 at $1-p$)\nHow many tosses, and what is your prediction?\n  $A^n \\in {0, 1}^n$\n With 2 flips, $A^2 \\in {00, 01, 10, 11}$    The prediction must be concise and accurate\n Accurate 90% of the time: $P(A^n) \\geq 0.9$ Concise prediction: $\\frac{|A^n|}{2^n}$    Running the Simulation Assume $p = 0.8$, but we must be accurate at least 90% of the time.\n We keep adding the most likely case to our prediction set until it exceeds 90%     n Prediction Set Accuracy Concision     1 {1, 0} 1.000 1.000   2 {11, 10, 01} 0.960 0.750   3 {111, 110, 101, 011, 100} 0.928 0.625    However, larger n doesn\u0026rsquo;t mean better\n $A^{n+1} = {x^n0, x^n1: x^n \\in A^n}$ $\\frac{|A^{n+1}|}{2^{n+1}} = \\frac{2|A^n|}{2\\cdot 2^n} = \\frac{|A^n|}{2^n}$  $$ P(A^{n+1}) = \\sum_{x^{n+1} \\in A^n} p(x^{n+1}) \\ = \\sum_{x^n \\in A^n} p(x^n0) + p(x^n1) \\ $$ $$ = \\sum_{x^n \\in A^n} p(x^n)\\cdot (1-p) + p(x^n)\\cdot p \\ = \\sum_{x^n \\in A^n} p(x^n) \\ = \\boxed{P(A^n)} $$\nAs n approaches infinity, concision will go to 0\n","permalink":"https://ericchanlee.com/blog/discotech_information_theory/","title":"Discover Caltech: Lecture on Information Theory"}]